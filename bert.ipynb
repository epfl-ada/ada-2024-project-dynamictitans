{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=DarkTurquoise>Import packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=DarkTurquoise>Dataset</font>\n",
    "\n",
    "We obtain the dataset from [this Kaggle link](https://www.kaggle.com/datasets/parulpandey/emotion-dataset/data), which is a dataset of English Twitter messages categorized into five basic emotions: sadness (0), joy (1), love (2), anger (3), and fear (4). We will use this dataset to train a BERT model and fine-tune it to perform emotion recognition on our movie plot summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Load the training/validation/testing dataset from the specified file path\\ntrain = pd.read_csv('data/data_for_training/training.csv')\\nval = pd.read_csv('data/data_for_training/validation.csv')\\ntest = pd.read_csv('data/data_for_training/test.csv')\\ntrain\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load the training/validation/testing dataset from the specified file path\n",
    "train = pd.read_csv('data/data_for_training/training.csv')\n",
    "val = pd.read_csv('data/data_for_training/validation.csv')\n",
    "test = pd.read_csv('data/data_for_training/test.csv')\n",
    "train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'neutral': 0, 'sadness': 1, 'enthusiasm': 2, 'worry': 3, 'surprise': 4, 'love': 5, 'fun': 6, 'hate': 7, 'happiness': 8, 'boredom': 9, 'relief': 10, 'anger': 11}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content  \\\n",
       "0         neutral  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2         sadness                Funeral ceremony...gloomy friday...   \n",
       "3      enthusiasm               wants to hang out with friends SOON!   \n",
       "4         neutral  @dannycastillo We want to trade with someone w...   \n",
       "...           ...                                                ...   \n",
       "39995     neutral                                   @JohnLloydTaylor   \n",
       "39996        love                     Happy Mothers Day  All my love   \n",
       "39997        love  Happy Mother's Day to all the mommies out ther...   \n",
       "39998   happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...   \n",
       "39999        love  @mopedronin bullet train from tokyo    the gf ...   \n",
       "\n",
       "       sentiment_label  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    2  \n",
       "4                    0  \n",
       "...                ...  \n",
       "39995                0  \n",
       "39996                5  \n",
       "39997                5  \n",
       "39998                8  \n",
       "39999                5  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/tweet_emotions/tweet_emotions.csv')\n",
    "data['sentiment'] = data['sentiment'].replace('empty', 'neutral')\n",
    "label_mapping = {label: idx for idx, label in enumerate(data['sentiment'].unique())}\n",
    "data['sentiment_label'] = data['sentiment'].map(label_mapping)\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>So glad the days almost over... Another nite o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>as landice said; &amp;quot;uhmazing.&amp;quot; you are...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>@nick_carter It says the video is private</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>@madeofhoney1 im sorry. i dont wanna cuz of ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>@mercadoasaria I don't know you, but you made ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>Flash lost my frisby on a roof. Sad days LOL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>Aww.. I lost 3 followers.  FOLLOW ME !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>@getape I had bad net issues on Weds so couldn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>Also, I designed the banner for http://mudroom...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21794</th>\n",
       "      <td>@tracey1972 Morning babe!  I plan on overdoing...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "19316  So glad the days almost over... Another nite o...      3\n",
       "29330  as landice said; &quot;uhmazing.&quot; you are...      5\n",
       "8755           @nick_carter It says the video is private      0\n",
       "2360   @madeofhoney1 im sorry. i dont wanna cuz of ho...      1\n",
       "14077  @mercadoasaria I don't know you, but you made ...      0\n",
       "...                                                  ...    ...\n",
       "8904        Flash lost my frisby on a roof. Sad days LOL      1\n",
       "3615              Aww.. I lost 3 followers.  FOLLOW ME !      7\n",
       "5140   @getape I had bad net issues on Weds so couldn...      1\n",
       "27383  Also, I designed the banner for http://mudroom...      5\n",
       "21794  @tracey1972 Morning babe!  I plan on overdoing...      8\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['content', 'sentiment_label']].rename(columns={'content': 'text', 'sentiment_label': 'label'})\n",
    "train, temp = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the 'text' column from the training/validation dataset\n",
    "'''train_encodings = tokenizer(list(train['text']), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val['text']), truncation=True, padding=True, max_length=128)'''\n",
    "\n",
    "train_encodings = tokenizer(list(train['text']), truncation=False, padding=True)\n",
    "val_encodings = tokenizer(list(val['text']), truncation=False, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow Dataset for training/validation data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings), \n",
    "    train['label']         \n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings), \n",
    "    val['label']          \n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained BERT model for sequence classification\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=12)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After three epochs, the model achieved a loss of 0.1232, accuracy of 94.27%, validation loss of 0.1704, and validation accuracy of 93.35%. We saved the model parameters and tested its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 11628s 6s/step - loss: 1.7947 - accuracy: 0.3739 - val_loss: 1.7199 - val_accuracy: 0.3832\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 12146s 6s/step - loss: 1.5811 - accuracy: 0.4515 - val_loss: 1.7790 - val_accuracy: 0.3702\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 12401s 6s/step - loss: 1.3013 - accuracy: 0.5584 - val_loss: 2.0221 - val_accuracy: 0.3545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2378facdb50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(16),\n",
    "    validation_data=val_dataset.batch(16),\n",
    "    epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly input several sentences to test the performance of the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Text: I feel like everything is falling apart., Predicted Label: 1\n",
      "Text: I can't stop smiling; everything feels perfect., Predicted Label: 8\n",
      "Text: You mean the world to me, and I cherish every moment with you., Predicted Label: 5\n",
      "Text: This is completely unacceptable; I am furious., Predicted Label: 7\n",
      "Text: The thought of losing everything keeps me awake at night., Predicted Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Example of unlabeled data\n",
    "unlabeled_texts = [\"I feel like everything is falling apart.\", \"I can't stop smiling; everything feels perfect.\",\n",
    "                \"You mean the world to me, and I cherish every moment with you.\",\"This is completely unacceptable; I am furious.\",\n",
    "                \"The thought of losing everything keeps me awake at night.\"]\n",
    "\n",
    "# Encode the unlabeled data\n",
    "unlabeled_encodings = tokenizer(unlabeled_texts, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "\n",
    "# Predict the labels for the unlabeled data\n",
    "predictions = model.predict(unlabeled_encodings.data)\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()\n",
    "\n",
    "# Print the predicted labels alongside their corresponding texts\n",
    "for text, label in zip(unlabeled_texts, predicted_labels):\n",
    "    print(f\"Text: {text}, Predicted Label: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert_finetuned_model_1\\\\tokenizer_config.json',\n",
       " './bert_finetuned_model_1\\\\special_tokens_map.json',\n",
       " './bert_finetuned_model_1\\\\vocab.txt',\n",
       " './bert_finetuned_model_1\\\\added_tokens.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./bert_finetuned_model_1\")\n",
    "tokenizer.save_pretrained(\"./bert_finetuned_model_1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
